{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDAvkYqAAs6S",
        "outputId": "0ca1c7bc-d8c6-4120-ecdd-9008346dc675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngx2dU6m-Ac7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! unzip '/content/drive/MyDrive/Dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import tensorflow.keras.backend as K\n",
        "from skimage import io\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Flatten, Dense, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "\n",
        "import glob\n",
        "from IPython.display import display\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "K4KHGh6fBMEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset(data_path):\n",
        "  train_dict, test_dict = {'image_name':[],'label':[]}, {'image_name':[],'label':[]}\n",
        "  for category in os.listdir(data_path):\n",
        "      cat_pathes = glob.glob(data_path+'/'+category+'/Train/*).png')\n",
        "      train_dict['image_name']+=cat_pathes\n",
        "      train_dict['label']+=[category]*len(cat_pathes)\n",
        "\n",
        "\n",
        "      cat_pathes = glob.glob(data_path+'/'+category+'/Test/*).png')\n",
        "      test_dict['image_name']+=cat_pathes\n",
        "      test_dict['label']+=[category]*len(cat_pathes)\n",
        "  train_df, test_df = pd.DataFrame.from_dict(train_dict).sample(frac=1), pd.DataFrame.from_dict(test_dict).sample(frac=1)\n",
        "\n",
        "  return train_df, test_df"
      ],
      "metadata": {
        "id": "H43fWduYHapB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/Dataset/Breast scans'\n",
        "train_df, test_df = dataset(data_path)"
      ],
      "metadata": {
        "id": "q0uksvi7N0vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tww6PbecvBSn",
        "outputId": "8d1152b0-eda9-4fd9-f3ca-76edceeff457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "benign       0.584435\n",
              "malignant    0.264317\n",
              "normal       0.151248\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['label'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmvwe1NrvL6S",
        "outputId": "976ff934-40af-4df5-d025-b91435169802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "benign       0.393939\n",
              "normal       0.303030\n",
              "malignant    0.303030\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FAST_RUN = True\n",
        "IMAGE_WIDTH=224\n",
        "IMAGE_HEIGHT=224\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "batch_size = 32\n",
        "LR = 1e-5"
      ],
      "metadata": {
        "id": "j3_93nYAOjih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight(class_weight='balanced',classes=train_df['label'].unique(), y=train_df['label'])\n",
        "class_weight = dict(zip([0,1,2], class_weights))\n",
        "class_weight[1]+=1"
      ],
      "metadata": {
        "id": "YNz7HmOTRaDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1.0/255, preprocessing_function=tf.keras.applications.mobilenet.preprocess_input\n",
        "                                   ,zoom_range=0.3,vertical_flip=True, horizontal_flip=True,\n",
        "                                   width_shift_range=0.2, height_shift_range=0.2,fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    \"\", \n",
        "    x_col='image_name',\n",
        "    y_col='label',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb1d76b7OWGi",
        "outputId": "11a95b47-e520-4a61-f9f6-8de8abf427aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 681 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1.0/255, preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)\n",
        "                                  #  ,zoom_range=0.3,vertical_flip=True, horizontal_flip=True,\n",
        "                                  #  width_shift_range=0.2, height_shift_range=0.2,fill_mode='nearest')\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    test_df, \n",
        "    \"\", \n",
        "    x_col='image_name',\n",
        "    y_col='label',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voWzg6aBPyHS",
        "outputId": "18bd4f7a-a04a-49c9-ec2e-23b7c38be0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 99 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v1 weights model\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(1e-4)#1e-5.5  lr=0.0000031623\n",
        "input_shape = (IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)\n",
        "base_model = tf.keras.applications.mobilenet.MobileNet(include_top=False, weights='imagenet',\n",
        "                                                    input_shape=input_shape)\n",
        "\n",
        "base_model.trainable=False\n",
        "\n",
        "X = Conv2D(filters = 2048, kernel_size = 1, padding='valid', name='conv_1')(base_model.output)\n",
        "X = Flatten()(X)\n",
        "X = Dense(1024,activation='relu', name='dense_1')(X)\n",
        "X = Dense(512,activation='relu', name='dense_2')(X)\n",
        "X = Dense(256,activation='relu', name='dense_3')(X)\n",
        "X = Dense(128,activation='relu', name='dense_4')(X)\n",
        "X = Dense(64,activation='relu', name='dense_5')(X)\n",
        "output = Dense(3,activation='sigmoid')(X)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "333333333333333333333333333333333333333333333333333333333333333333"
      ],
      "metadata": {
        "id": "sdQ89_4KyPGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(1e-4)#1e-5.5  lr=0.0000031623\n",
        "input_shape = (IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)\n",
        "base_model = tf.keras.applications.mobilenet.MobileNet(include_top=False, weights=None,\n",
        "                                                    input_shape=input_shape)\n",
        "\n",
        "X = Conv2D(filters = 2048, kernel_size = 1, padding='valid', name='conv_1')(base_model.output)\n",
        "X = Flatten()(X)\n",
        "X = Dense(1024,activation='relu')(X)\n",
        "X = Dense(512,activation='relu')(X)\n",
        "X = Dense(256,activation='relu')(X)\n",
        "X = Dense(128,activation='relu')(X)\n",
        "X = Dense(64,activation='relu')(X)\n",
        "output = Dense(3,activation='sigmoid')(X)\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/breast_calssifier.h5')\n",
        "\n",
        "model.trainable=False\n",
        "for layer in model.layers[-3:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=[tf.keras.metrics.AUC()],\n",
        "              optimizer=opt)\n",
        "# model.save()"
      ],
      "metadata": {
        "id": "rQSN8YuIKeky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# opt = tf.keras.optimizers.Adam(lr=1e-3)\n",
        "# input_shape = IMAGE_SIZE + (3,) \n",
        "\n",
        "# input_layer = tf.keras.Input(shape=input_shape)\n",
        "# X = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(input_layer)\n",
        "# X = Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(X)\n",
        "\n",
        "# X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
        "# X = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(X)\n",
        "# X = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(X)\n",
        "\n",
        "# X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
        "# X = Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(X)\n",
        "# X = Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(X)\n",
        "# X = Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(X)\n",
        "# X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
        "\n",
        "# X = Flatten()(X)\n",
        "# X = Dense(units=2048, activation='relu')(X)\n",
        "# X = Dropout(0.6)(X)\n",
        "# X = Dense(units=2048, activation='relu')(X)\n",
        "# output = Dense(3,activation='sigmoid')(X)\n",
        "# model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', metrics=[tf.keras.metrics.AUC()],\n",
        "#               optimizer=opt)"
      ],
      "metadata": {
        "id": "AYkFlwTpSWQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef91057-ff55-4689-a30f-f1a8f3318a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt = tf.keras.optimizers.Adam(1e-4)#1e-5.5  lr=0.0000031623\n",
        "# input_shape = (IMAGE_WIDTH,IMAGE_HEIGHT,IMAGE_CHANNELS)\n",
        "# base_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet',\n",
        "#                                                     input_shape=input_shape)\n",
        "\n",
        "# base_model.trainable=False\n",
        "# # for layer in base_model.layers[-5:]:\n",
        "# #   layer.trainable=True\n",
        "\n",
        "# X = Conv2D(filters = 2048, kernel_size = 1, padding='valid', name='conv_1')(base_model.output)\n",
        "# X = Conv2D(filters = 1024, kernel_size = 1, padding='valid')(X)\n",
        "# # X = Conv2D(filters = 512, kernel_size = 1, padding='valid')(X)\n",
        "# X = Flatten()(X)\n",
        "# X = Dense(1024,activation='relu', name='dense_1')(X)\n",
        "# X = Dense(512,activation='relu', name='dense_2')(X)\n",
        "# X = Dense(256,activation='relu', name='dense_3')(X)\n",
        "# X = Dense(128,activation='relu', name='dense_4')(X)\n",
        "# X = Dense(64,activation='relu', name='dense_5')(X)\n",
        "# output = Dense(3,activation='sigmoid')(X)\n",
        "# model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# # model.summary()\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', metrics=[tf.keras.metrics.AUC()],\n",
        "#               optimizer=opt)"
      ],
      "metadata": {
        "id": "ymMZqpc89YPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
        "# pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']).tail(50)"
      ],
      "metadata": {
        "id": "VjsKHk83cYsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/CV_project/breast_classifier_v5.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_auc',\n",
        "    mode='max')\n",
        "callbacks = [model_checkpoint_callback]"
      ],
      "metadata": {
        "id": "tE78ZjK4QJiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_train = train_df.shape[0]\n",
        "total_validate = test_df.shape[0]\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "CetgdqmLUWT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5 if FAST_RUN else 10\n",
        "history = model.fit(train_generator, epochs=epochs,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoTxtSocUcXV",
        "outputId": "beb25584-c04e-4ac4-a925-30b94494bca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 19s 870ms/step - loss: 0.3590 - auc_5: 0.9373 - val_loss: 0.8197 - val_auc_5: 0.8607\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 19s 925ms/step - loss: 0.2870 - auc_5: 0.9423 - val_loss: 0.8239 - val_auc_5: 0.8614\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 18s 897ms/step - loss: 0.3562 - auc_5: 0.9432 - val_loss: 0.8278 - val_auc_5: 0.8613\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 18s 896ms/step - loss: 0.2970 - auc_5: 0.9415 - val_loss: 0.8399 - val_auc_5: 0.8584\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 17s 790ms/step - loss: 0.3872 - auc_5: 0.9368 - val_loss: 0.7483 - val_auc_5: 0.8653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jckY_GQ9i6o8",
        "outputId": "d0fa6c8b-87f4-4f42-bafc-5c9a4533fddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 187ms/step - loss: 0.8167 - auc: 0.8624\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8167282342910767, 0.8624374866485596]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}